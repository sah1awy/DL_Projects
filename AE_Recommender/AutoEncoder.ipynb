{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a976ac6-690c-42fe-b0b4-ba6c1f803467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.parallel\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318cc9e4-80fb-4cf8-b604-1f114caee08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('ml-100k/u1.base',header=None,delimiter='\\t')\n",
    "test_data = pd.read_csv('ml-100k/u1.test',header=None,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b056569-a3c7-4fa5-b86c-aee8e9aa5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array(training_data,dtype=int)\n",
    "test_data = np.array(test_data,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947d19ee-d606-4fb7-b045-4728977df6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         1,         5, 874965758],\n",
       "       [        1,         2,         3, 876893171],\n",
       "       [        1,         3,         4, 878542960],\n",
       "       [        1,         4,         3, 876893119],\n",
       "       [        1,         5,         3, 889751712],\n",
       "       [        1,         7,         4, 875071561],\n",
       "       [        1,         8,         1, 875072484],\n",
       "       [        1,         9,         5, 878543541],\n",
       "       [        1,        11,         2, 875072262],\n",
       "       [        1,        13,         5, 875071805]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb3b4f7a-c084-443b-88d4-bac9424950a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_movies = int(max(max(training_data[:,1]),max(test_data[:,1])))\n",
    "nb_users = int(max(max(training_data[:,0]),max(test_data[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa66573-0ca0-4dbe-838c-1d114bd1fda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12b9147-3bbd-45bb-9675-2f6171f199fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c9974c8-0d0e-4149-9f9e-8231837a2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for i in range(1,nb_users+1):\n",
    "        mov = data[data[:,0] == i][:,1]\n",
    "        rate = data[data[:,0]==i][:,2]\n",
    "        rating = np.zeros(nb_movies)\n",
    "        rating[mov-1] = rate\n",
    "        new_data.append(list(rating))\n",
    "    return new_data\n",
    "\n",
    "training_data = convert(training_data)\n",
    "test_data = convert(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43f4e127-b358-46a2-bf25-0307ab989159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "177db281-7329-414d-8a88-b33fb5ba8a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a998807b-210e-4a20-ad78-ed396b366324",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torch.FloatTensor(training_data)\n",
    "test_data = torch.FloatTensor(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64839ce6-8ab3-4da8-9a7a-480bd394288a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train loss: tensor(1.7709)\n",
      "epoch: 2 train loss: tensor(1.0968)\n",
      "epoch: 3 train loss: tensor(1.0534)\n",
      "epoch: 4 train loss: tensor(1.0384)\n",
      "epoch: 5 train loss: tensor(1.0310)\n",
      "epoch: 6 train loss: tensor(1.0264)\n",
      "epoch: 7 train loss: tensor(1.0240)\n",
      "epoch: 8 train loss: tensor(1.0218)\n",
      "epoch: 9 train loss: tensor(1.0207)\n",
      "epoch: 10 train loss: tensor(1.0197)\n",
      "epoch: 11 train loss: tensor(1.0190)\n",
      "epoch: 12 train loss: tensor(1.0185)\n",
      "epoch: 13 train loss: tensor(1.0179)\n",
      "epoch: 14 train loss: tensor(1.0176)\n",
      "epoch: 15 train loss: tensor(1.0171)\n",
      "epoch: 16 train loss: tensor(1.0167)\n",
      "epoch: 17 train loss: tensor(1.0164)\n",
      "epoch: 18 train loss: tensor(1.0166)\n",
      "epoch: 19 train loss: tensor(1.0165)\n",
      "epoch: 20 train loss: tensor(1.0162)\n",
      "epoch: 21 train loss: tensor(1.0159)\n",
      "epoch: 22 train loss: tensor(1.0161)\n",
      "epoch: 23 train loss: tensor(1.0160)\n",
      "epoch: 24 train loss: tensor(1.0157)\n",
      "epoch: 25 train loss: tensor(1.0155)\n",
      "epoch: 26 train loss: tensor(1.0156)\n",
      "epoch: 27 train loss: tensor(1.0153)\n",
      "epoch: 28 train loss: tensor(1.0150)\n",
      "epoch: 29 train loss: tensor(1.0134)\n",
      "epoch: 30 train loss: tensor(1.0118)\n",
      "epoch: 31 train loss: tensor(1.0096)\n",
      "epoch: 32 train loss: tensor(1.0093)\n",
      "epoch: 33 train loss: tensor(1.0053)\n",
      "epoch: 34 train loss: tensor(1.0053)\n",
      "epoch: 35 train loss: tensor(1.0015)\n",
      "epoch: 36 train loss: tensor(0.9994)\n",
      "epoch: 37 train loss: tensor(0.9976)\n",
      "epoch: 38 train loss: tensor(0.9955)\n",
      "epoch: 39 train loss: tensor(0.9939)\n",
      "epoch: 40 train loss: tensor(0.9922)\n",
      "epoch: 41 train loss: tensor(0.9882)\n",
      "epoch: 42 train loss: tensor(0.9897)\n",
      "epoch: 43 train loss: tensor(0.9855)\n",
      "epoch: 44 train loss: tensor(0.9856)\n",
      "epoch: 45 train loss: tensor(0.9815)\n",
      "epoch: 46 train loss: tensor(0.9829)\n",
      "epoch: 47 train loss: tensor(0.9796)\n",
      "epoch: 48 train loss: tensor(0.9792)\n",
      "epoch: 49 train loss: tensor(0.9752)\n",
      "epoch: 50 train loss: tensor(0.9761)\n",
      "epoch: 51 train loss: tensor(0.9723)\n",
      "epoch: 52 train loss: tensor(0.9733)\n",
      "epoch: 53 train loss: tensor(0.9697)\n",
      "epoch: 54 train loss: tensor(0.9683)\n",
      "epoch: 55 train loss: tensor(0.9708)\n",
      "epoch: 56 train loss: tensor(0.9751)\n",
      "epoch: 57 train loss: tensor(0.9711)\n",
      "epoch: 58 train loss: tensor(0.9706)\n",
      "epoch: 59 train loss: tensor(0.9659)\n",
      "epoch: 60 train loss: tensor(0.9636)\n",
      "epoch: 61 train loss: tensor(0.9628)\n",
      "epoch: 62 train loss: tensor(0.9684)\n",
      "epoch: 63 train loss: tensor(0.9690)\n",
      "epoch: 64 train loss: tensor(0.9621)\n",
      "epoch: 65 train loss: tensor(0.9609)\n",
      "epoch: 66 train loss: tensor(0.9643)\n",
      "epoch: 67 train loss: tensor(0.9630)\n",
      "epoch: 68 train loss: tensor(0.9612)\n",
      "epoch: 69 train loss: tensor(0.9593)\n",
      "epoch: 70 train loss: tensor(0.9603)\n",
      "epoch: 71 train loss: tensor(0.9583)\n",
      "epoch: 72 train loss: tensor(0.9595)\n",
      "epoch: 73 train loss: tensor(0.9565)\n",
      "epoch: 74 train loss: tensor(0.9561)\n",
      "epoch: 75 train loss: tensor(0.9537)\n",
      "epoch: 76 train loss: tensor(0.9532)\n",
      "epoch: 77 train loss: tensor(0.9565)\n",
      "epoch: 78 train loss: tensor(0.9599)\n",
      "epoch: 79 train loss: tensor(0.9568)\n",
      "epoch: 80 train loss: tensor(0.9559)\n",
      "epoch: 81 train loss: tensor(0.9518)\n",
      "epoch: 82 train loss: tensor(0.9515)\n",
      "epoch: 83 train loss: tensor(0.9503)\n",
      "epoch: 84 train loss: tensor(0.9509)\n",
      "epoch: 85 train loss: tensor(0.9482)\n",
      "epoch: 86 train loss: tensor(0.9498)\n",
      "epoch: 87 train loss: tensor(0.9454)\n",
      "epoch: 88 train loss: tensor(0.9470)\n",
      "epoch: 89 train loss: tensor(0.9441)\n",
      "epoch: 90 train loss: tensor(0.9466)\n",
      "epoch: 91 train loss: tensor(0.9425)\n",
      "epoch: 92 train loss: tensor(0.9460)\n",
      "epoch: 93 train loss: tensor(0.9409)\n",
      "epoch: 94 train loss: tensor(0.9425)\n",
      "epoch: 95 train loss: tensor(0.9404)\n",
      "epoch: 96 train loss: tensor(0.9432)\n",
      "epoch: 97 train loss: tensor(0.9387)\n",
      "epoch: 98 train loss: tensor(0.9430)\n",
      "epoch: 99 train loss: tensor(0.9385)\n",
      "epoch: 100 train loss: tensor(0.9401)\n",
      "epoch: 101 train loss: tensor(0.9374)\n",
      "epoch: 102 train loss: tensor(0.9401)\n",
      "epoch: 103 train loss: tensor(0.9369)\n",
      "epoch: 104 train loss: tensor(0.9390)\n",
      "epoch: 105 train loss: tensor(0.9349)\n",
      "epoch: 106 train loss: tensor(0.9486)\n",
      "epoch: 107 train loss: tensor(0.9439)\n",
      "epoch: 108 train loss: tensor(0.9427)\n",
      "epoch: 109 train loss: tensor(0.9397)\n",
      "epoch: 110 train loss: tensor(0.9413)\n",
      "epoch: 111 train loss: tensor(0.9381)\n",
      "epoch: 112 train loss: tensor(0.9394)\n",
      "epoch: 113 train loss: tensor(0.9374)\n",
      "epoch: 114 train loss: tensor(0.9375)\n",
      "epoch: 115 train loss: tensor(0.9341)\n",
      "epoch: 116 train loss: tensor(0.9389)\n",
      "epoch: 117 train loss: tensor(0.9370)\n",
      "epoch: 118 train loss: tensor(0.9370)\n",
      "epoch: 119 train loss: tensor(0.9333)\n",
      "epoch: 120 train loss: tensor(0.9370)\n",
      "epoch: 121 train loss: tensor(0.9350)\n",
      "epoch: 122 train loss: tensor(0.9348)\n",
      "epoch: 123 train loss: tensor(0.9326)\n",
      "epoch: 124 train loss: tensor(0.9352)\n",
      "epoch: 125 train loss: tensor(0.9312)\n",
      "epoch: 126 train loss: tensor(0.9330)\n",
      "epoch: 127 train loss: tensor(0.9306)\n",
      "epoch: 128 train loss: tensor(0.9327)\n",
      "epoch: 129 train loss: tensor(0.9296)\n",
      "epoch: 130 train loss: tensor(0.9314)\n",
      "epoch: 131 train loss: tensor(0.9296)\n",
      "epoch: 132 train loss: tensor(0.9307)\n",
      "epoch: 133 train loss: tensor(0.9283)\n",
      "epoch: 134 train loss: tensor(0.9301)\n",
      "epoch: 135 train loss: tensor(0.9281)\n",
      "epoch: 136 train loss: tensor(0.9293)\n",
      "epoch: 137 train loss: tensor(0.9271)\n",
      "epoch: 138 train loss: tensor(0.9284)\n",
      "epoch: 139 train loss: tensor(0.9262)\n",
      "epoch: 140 train loss: tensor(0.9280)\n",
      "epoch: 141 train loss: tensor(0.9258)\n",
      "epoch: 142 train loss: tensor(0.9273)\n",
      "epoch: 143 train loss: tensor(0.9265)\n",
      "epoch: 144 train loss: tensor(0.9274)\n",
      "epoch: 145 train loss: tensor(0.9250)\n",
      "epoch: 146 train loss: tensor(0.9270)\n",
      "epoch: 147 train loss: tensor(0.9247)\n",
      "epoch: 148 train loss: tensor(0.9257)\n",
      "epoch: 149 train loss: tensor(0.9242)\n",
      "epoch: 150 train loss: tensor(0.9253)\n",
      "epoch: 151 train loss: tensor(0.9243)\n",
      "epoch: 152 train loss: tensor(0.9263)\n",
      "epoch: 153 train loss: tensor(0.9232)\n",
      "epoch: 154 train loss: tensor(0.9245)\n",
      "epoch: 155 train loss: tensor(0.9223)\n",
      "epoch: 156 train loss: tensor(0.9240)\n",
      "epoch: 157 train loss: tensor(0.9223)\n",
      "epoch: 158 train loss: tensor(0.9237)\n",
      "epoch: 159 train loss: tensor(0.9221)\n",
      "epoch: 160 train loss: tensor(0.9232)\n",
      "epoch: 161 train loss: tensor(0.9208)\n",
      "epoch: 162 train loss: tensor(0.9224)\n",
      "epoch: 163 train loss: tensor(0.9204)\n",
      "epoch: 164 train loss: tensor(0.9222)\n",
      "epoch: 165 train loss: tensor(0.9207)\n",
      "epoch: 166 train loss: tensor(0.9221)\n",
      "epoch: 167 train loss: tensor(0.9199)\n",
      "epoch: 168 train loss: tensor(0.9218)\n",
      "epoch: 169 train loss: tensor(0.9195)\n",
      "epoch: 170 train loss: tensor(0.9212)\n",
      "epoch: 171 train loss: tensor(0.9187)\n",
      "epoch: 172 train loss: tensor(0.9205)\n",
      "epoch: 173 train loss: tensor(0.9186)\n",
      "epoch: 174 train loss: tensor(0.9204)\n",
      "epoch: 175 train loss: tensor(0.9179)\n",
      "epoch: 176 train loss: tensor(0.9199)\n",
      "epoch: 177 train loss: tensor(0.9178)\n",
      "epoch: 178 train loss: tensor(0.9189)\n",
      "epoch: 179 train loss: tensor(0.9179)\n",
      "epoch: 180 train loss: tensor(0.9188)\n",
      "epoch: 181 train loss: tensor(0.9176)\n",
      "epoch: 182 train loss: tensor(0.9191)\n",
      "epoch: 183 train loss: tensor(0.9171)\n",
      "epoch: 184 train loss: tensor(0.9193)\n",
      "epoch: 185 train loss: tensor(0.9178)\n",
      "epoch: 186 train loss: tensor(0.9190)\n",
      "epoch: 187 train loss: tensor(0.9169)\n",
      "epoch: 188 train loss: tensor(0.9184)\n",
      "epoch: 189 train loss: tensor(0.9164)\n",
      "epoch: 190 train loss: tensor(0.9182)\n",
      "epoch: 191 train loss: tensor(0.9167)\n",
      "epoch: 192 train loss: tensor(0.9178)\n",
      "epoch: 193 train loss: tensor(0.9162)\n",
      "epoch: 194 train loss: tensor(0.9177)\n",
      "epoch: 195 train loss: tensor(0.9161)\n",
      "epoch: 196 train loss: tensor(0.9172)\n",
      "epoch: 197 train loss: tensor(0.9159)\n",
      "epoch: 198 train loss: tensor(0.9172)\n",
      "epoch: 199 train loss: tensor(0.9154)\n",
      "epoch: 200 train loss: tensor(0.9164)\n"
     ]
    }
   ],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(SAE,self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies,20)\n",
    "        self.fc2 = nn.Linear(20,10)\n",
    "        self.fc3 = nn.Linear(10,20)\n",
    "        self.fc4 = nn.Linear(20,nb_movies)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(),lr=0.01,weight_decay=0.5)\n",
    "epochs = 200\n",
    "for epoch in range(1,epochs+1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id in range(nb_users):\n",
    "        input = Variable(training_data[id]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0: \n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output,target)\n",
    "            mean_corrector =  nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print(\"epoch: \"+str(epoch)+\" train loss: \"+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b090e47-c9aa-45ad-bf07-de432a7aedd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1338)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d58a9c3-ff32-4b18-aa94-442fe443d278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.011904761904763"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_corrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eff133c0-4118-4ddd-bba0-1752f03c25d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: tensor(1.8828)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "for id in range(nb_users):\n",
    "    input = Variable(training_data[id]).unsqueeze(0)\n",
    "    target = Variable(test_data[id]).unsqueeze(0)\n",
    "    if torch.sum(target.data > 0) > 0: \n",
    "        output = sae(input)\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output,target)\n",
    "        mean_corrector =  nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
    "        s += 1.\n",
    "print(\"train loss: \"+str(train_loss/s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
